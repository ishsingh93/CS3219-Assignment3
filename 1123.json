{"algorithms": {
    "version": 110505,
    "algorithm": [
        {
            "name": "SectLabel",
            "variant": {
                "no": 0,
                "listItem": [
                    {
                        "confidence": 0.619022,
                        "content": "1) t(wj I w,, ) models the co-occurrence"
                    },
                    {
                        "confidence": 0.745597,
                        "content": "3) n(O, I w,) models the fertility of words, which"
                    },
                    {
                        "confidence": 0.928823928571429,
                        "content": "1) Hu is the method described in (Hu et al., 2004),\nwhich extracted opinion targets by using adjacent\nrule.\n2) DP is the method described in (Qiu et al., 2011),\nwhich used Double Propagation algorithm to\nextract opinion targets depending on syntactic\nrelations between words.\n3) Zhang is the method described in (Zhang et al.,\n2010), which is an extension of DP. They extracted\nopinion targets candidates using syntactic patterns\nand other specific patterns. Then HITS (Kleinberg\n1999) algorithm combined with candidate\nfrequency is employed to rank the results for\nopinion target extraction."
                    },
                    {
                        "confidence": 0.983993235294117,
                        "content": "1) Ours achieves performance improvement over\nother methods. This indicates that our method\nbased on word-based translation model is\neffective for opinion target extraction.\n2) The graph-based methods (Ours and Zhang)\noutperform the methods using Double\nPropagation (DP). Similar observations have\nbeen made by Zhang et al. (2010). The reason\nis that graph-based methods extract opinion\ntargets in a global framework and they can\neffectively avoid the error propagation made\nby traditional methods based on Double\nPropagation. Moreover, Ours outperforms\nZhang. We believe the reason is that Ours\nconsider the opinion relevance and the\ncandidate importance in a unified graph-based\nframework. By contrast, Zhang only simply"
                    }
                ],
                "figure": {
                    "confidence": 0.50752,
                    "content": "1 http://books.google.com/ngrams/datasets\n1350"
                },
                "author": {
                    "confidence": 0.998682,
                    "content": "Kang Liu, Liheng Xu, Jun Zhao"
                },
                "confidence": 0,
                "equation": [
                    {
                        "confidence": 0.9853132,
                        "content": "A =argmax (  |)\nP A S (1)\n( i , a i )\nS = {w\u201e w2, ..., wn } , the word alignment\nA = {(i, a;) I i E [l, n] } can be obtained by"
                    },
                    {
                        "confidence": 0.407303,
                        "content": "ˆ\nA"
                    },
                    {
                        "confidence": 0.991166,
                        "content": "C&quot;, = M` x Mx C` (6)"
                    },
                    {
                        "confidence": 0.863308,
                        "content": "C&quot;'=(1\u2014A)xM`xMx C`+AxS (7)"
                    },
                    {
                        "confidence": 0.833157,
                        "content": "C=AX(I\u2014(1\u2014A)xM` xM)-,Xs (8)"
                    },
                    {
                        "confidence": 0.930678,
                        "content": "C=Ax[I+B+ +B&quot;]xS (9)"
                    }
                ],
                "subsectionHeader": [
                    {
                        "confidence": 0.511544,
                        "content": "Translation"
                    },
                    {
                        "confidence": 0.999483,
                        "content": "3.1 Method Framework"
                    },
                    {
                        "confidence": 0.998497,
                        "content": "3.2 Mining associations between opinion"
                    },
                    {
                        "confidence": 0.996016,
                        "content": "3.3 Candidate Confidence Estimation"
                    },
                    {
                        "confidence": 0.997573,
                        "content": "4.1 Datasets and Evaluation Metrics"
                    },
                    {
                        "confidence": 0.838498,
                        "content": "4.2 Our Methods vs. State-of-art Methods"
                    },
                    {
                        "confidence": 0.998323,
                        "content": "4.3 Effect of Word-based Translation Model"
                    },
                    {
                        "confidence": 0.995505,
                        "content": "4.4 Effect of Our Graph-based Method"
                    },
                    {
                        "confidence": 0.9373985,
                        "content": "4.5 Parameter Influences\n4.5.1 Effect of Different WTMs"
                    },
                    {
                        "confidence": 0.932233,
                        "content": "4.5.2 Effect of"
                    }
                ],
                "footnote": {
                    "confidence": 0.78844,
                    "content": "3 http://sifaka.cs.uiuc.edu/~wang296/Data/index.html\n4 http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html"
                },
                "title": {
                    "confidence": 0.990152,
                    "content": "Opinion Target Extraction Using Word-Based Translation Model"
                },
                "reference": {
                    "confidence": 0.998724304347826,
                    "content": "Peter F. Brown, Stephen A. Della Pietra, Vincent J.\nDella Pietra, and Robert L. Mercer. 1993. The\nMathematics of Statistical Machine Translation:\nParameter Estimation. Computational Linguistics,\n19(2): 263-311.\nXiaowen Ding, Bing Liu and Philip S. Yu. 2008. A\nHolistic Lexicon-Based Approach to Opinion Mining.\nIn Proceedings of WSDM 2008.\nXiaowen Ding and Bing Liu. 2010. Resolving Object\nand Attribute Reference in Opinion Mining. In\nProceedings of COLING 2010.\nMingqin Hu and Bing Liu. 2004. Mining and\nSummarizing Customer Reviews. In Proceedings of\nKDD 2004\nMinqing Hu and Bing Liu. 2004. Mining Opinion\nFeatures in Customer Reviews. In Proceedings of\nAAAI-2004, San Jose, USA, July 2004.\nWei Jin and Huang Hay Ho. A Novel Lexicalized\nHMM-based Learning Framework for Web Opinion\nMining. In Proceedings of ICML 2009.\nJon Klernberg. 1999. Authoritative Sources in\nHyperlinked Environment. Journal of the ACM 46(5):\n604-632\nZhuang Li, Feng Jing, Xiao-yan Zhu. 2006. Movie\nReview Mining and Summarization. In Proceedings\nof CIKM 2006\nFangtao Li, Chao Han, Minlie Huang and Xiaoyan Zhu.\n2010. Structure-Aware Review Mining and\nSummarization. In Proceedings of COLING 2010.\nZhichao Li, Min Zhang, Shaoping Ma, Bo Zhou, Yu\nSun. Automatic Extraction for Product Feature\nWords from Comments on the Web. In Proceedings\nof AIRS 2009.\nBing Liu, Hu Mingqing and Cheng Junsheng. 2005.\nOpinion Observer: Analyzing and Comparing\nOpinions on the Web. In Proceedings of WWW 2005\nBing Liu. 2006. Web Data Mining: Exploring\nHyperlinks, contents and usage data. Springer, 2006\nBing Liu. 2010. Sentiment analysis and subjectivity.\nHandbook of Natural Language Processing, second\nedition, 2010.\nYang Liu, Qun Liu, and Shouxun Lin. 2010.\nDiscriminative word alignment by linear modeling.\nComputational Linguistics, 36(3):303\u2013339.\nZhanyi Liu, Haifeng Wang, Hua Wu and Sheng Li.\n2009. Collocation Extraction Using Monolingual\nWord Alignment Model. In Proceedings of EMNLP\n2009.\nTengfei Ma and Xiaojun Wan. 2010. Opinion Target\nExtraction in Chinese News Comments. In\nProceedings of COLING 2010.\nPopescu, Ana-Maria and Oren, Etzioni. 2005.\nExtracting produt fedatures and opinions from\nreviews. In Proceedings of EMNLP 2005\nGuang Qiu, Bing Liu., Jiajun Bu and Chun Che. 2009.\nExpanding Domain Sentiment Lexicon through\nDouble Popagation. In Proceedings of IJCAI 2009\nGuang Qiu, Bing Liu, Jiajun Bu and Chun Chen. 2011.\nOpinion Word Expansion and Target Extraction\n1355\nthrough Double Propagation. Computational\nLinguistics, March 2011, Vol. 37, No. 1: 9.27\nQi Su, Xinying Xu., Honglei Guo, Zhili Guo, Xian Wu,\nXiaoxun Zhang, Bin Swen and Zhong Su. 2008.\nHidden Sentiment Association in Chinese Web\nOpinion Mining. In Proceedings of WWW 2008\nBo Wang, Houfeng Wang. Bootstrapping both Product\nFeatures and Opinion Words from Chinese Customer\nReviews with Cross-Inducing. In Proceedings of\nIJCNLP 2008.\nHongning Wang, Yue Lu and Chengxiang Zhai. 2011.\nLatent Aspect Rating Analysis without Aspect\nKeyword Supervision. In Proceedings of KDD 2011.\nYuanbin Wu, Qi Zhang, Xuangjing Huang and Lide\nWu, 2009, Phrase Dependency Parsing For Opinion\nMining, In Proceedings of EMNLP 2009\nLei Zhang, Bing Liu, Suk Hwan Lim and Eamonn\nO\u2019Brien-Strain. 2010. Extracting and Ranking\nProduct Features in Opinion Documents. In\nProceedings of COLING 2010.\nQi Zhang, Yuanbin Wu, Tao Li, Mitsunori Ogihara,\nJoseph Johnson, Xuanjing Huang. 2009. Mining\nProduct Reviews Based on Shallow Dependency\nParsing, In Proceedings of SIGIR 2009.\nGuangyou Zhou, Li Cai, Jun Zhao and Kang Liu. 2011.\nPhrase-based Translation Model for Question\nRetrieval in Community Question Answer Archives.\nIn Proceedings of ACL 2011.\nJingbo Zhu, Huizhen Wang, Benjamin K. Tsou and\nMuhua Zhu. 2009. Multi-aspect Opinion Polling\nfrom Textual Reviews. In Proceedings of CIKM\n2009."
                },
                "bodyText": [
                    {
                        "confidence": 0.999963,
                        "content": "This paper proposes a novel approach to\nextract opinion targets based on word-\nbased translation model (WTM). At first,\nwe apply WTM in a monolingual scenario\nto mine the associations between opinion\ntargets and opinion words. Then, a graph-\nbased algorithm is exploited to extract\nopinion targets, where candidate opinion\nrelevance estimated from the mined\nassociations, is incorporated with candidate\nimportance to generate a global measure.\nBy using WTM, our method can capture\nopinion relations more precisely, especially\nfor long-span relations. In particular,\ncompared with previous syntax-based\nmethods, our method can effectively avoid\nnoises from parsing errors when dealing\nwith informal texts in large Web corpora.\nBy using graph-based algorithm, opinion\ntargets are extracted in a global process,\nwhich can effectively alleviate the problem\nof error propagation in traditional\nbootstrap-based methods, such as Double\nPropagation. The experimental results on\nthree real world datasets in different sizes\nand languages show that our approach is\nmore effective and robust than state-of-art\nmethods."
                    },
                    {
                        "confidence": 0.999792818181818,
                        "content": "With the rapid development of e-commerce, most\ncustomers express their opinions on various kinds\nof entities, such as products and services. These\nreviews not only provide customers with useful\ninformation for reference, but also are valuable for\nmerchants to get the feedback from customers and\nenhance the qualities of their products or services.\nTherefore, mining opinions from these vast\namounts of reviews becomes urgent, and has\nattracted a lot of attentions from many researchers.\nIn opinion mining, one fundamental problem is\nopinion target extraction. This task is to extract\nitems which opinions are expressed on. In reviews,\nopinion targets are usually nouns/noun phrases.\nFor example, in the sentence of \u201cThe phone has a\ncolorful and even amazing screen\u201d, \u201cscreen\u201d is an\nopinion target. In online product reviews, opinion\ntargets often are products or product features, so\nthis task is also named as product feature\nextraction in previous work (Hu et al., 2004; Ding\net al., 2008; Liu et al., 2005; Popescu et al., 2005;\nWu et al., 2005; Su et al., 2008).\nTo extract opinion targets, many studies\nregarded opinion words as strong indicators (Hu et\nal., 2004; Popescu et al., 2005; Liu et al., 2005;\nQiu et al., 2011; Zhang et al., 2010), which is\nbased on the observation that opinion words are\nusually located around opinion targets, and there\nare associations between them. Therefore, most\npervious methods iteratively extracted opinion\ntargets depending upon the associations between\nopinion words and opinion targets (Qiu et al., 2011;\nZhang et al., 2010). For example, \u201ccolorful\u201d and\n\u201camazing\u201d is usually used to modify \u201cscreen\u201d in\nreviews about cell phone, so there are strong\nassociations between them. If \u201ccolorful\u201d and\n\u201camazing\u201d had been known to be opinion words,\n\u201cscreen\u201d is likely to be an opinion target in this\ndomain. In addition, the extracted opinion targets\ncan be used to expand more opinion words\naccording to their associations. It\u2019s a mutual\nreinforcement procedure.\nTherefore, mining associations between opinion\ntargets and opinion words is a key for opinion"
                    },
                    {
                        "confidence": 0.996934569767442,
                        "content": "target extraction (Wu et al., 2009). To this end,\nmost previous methods (Hu et al., 2004; Ding et al.,\n2004; Wang et al., 2008), named as adjacent\nmethods, employed the adjacent rule, where an\nopinion target was regarded to have opinion\nrelations with the surrounding opinion words in a\ngiven window. However, because of the limitation\nof window size, opinion relations cannot be\ncaptured precisely, especially for long-span\nrelations, which would hurt estimating associations\nbetween opinion targets and opinion words. To\nresolve this problem, several studies exploited\nsyntactic information such as dependency trees\n(Popescu et al., 2005; Qiu et al., 2009; Qiu et al.,\n2011; Wu et al., 2009; Zhang et al., 2010). If the\nsyntactic relation between an opinion word and an\nopinion target satisfied a designed pattern, then\nthere was an opinion relation between them.\nExperiments consistently reported that syntax-\nbased methods could yield better performance than\nadjacent methods for small or medium corpora\n(Zhang et al., 2010). The performance of syntax-\nbased methods heavily depends on the parsing\nperformance. However, online reviews are often\ninformal texts (including grammar mistakes, typos,\nimproper punctuations etc.). As a result, parsing\nmay generate many mistakes. Thus, for large\ncorpora from Web including a great deal of\ninformal texts, these syntax-based methods may\nsuffer from parsing errors and introduce many\nnoises. Furthermore, this problem maybe more\nserious on non-English language reviews, such as\nChinese reviews, because that the performances of\nparsing on these languages are often worse than\nthat on English.\nTo overcome the weakness of the two kinds of\nmethods mentioned above, we propose a novel\nunsupervised approach to extract opinion targets\nby using word-based translation model (WTM).\nWe formulate identifying opinion relations\nbetween opinion targets and opinion words as a\nword alignment task. We argue that an opinion\ntarget can find its corresponding modifier through\nmonolingual word alignment. For example in\nFigure 1, the opinion words \u201ccolorful\u201d and\n\u201camazing\u201d are aligned with the target \u201cscreen\u201d\nthrough word alignment. To this end, we use WTM\nto perform monolingual word alignment for mining\nassociations between opinion targets and opinion\nwords. In this process, several factors, such as\nword co-occurrence frequencies, word positions\netc., can be considered globally. Compared with\nadjacent methods, WTM doesn\u2019t identify opinion\nrelations between words in a given window, so\nlong-span relations can be effectively captured\n(Liu et al., 2009). Compared with syntax-based\nmethods, without using parsing, WTM can\neffectively avoid errors from parsing informal texts.\nSo it will be more robust. In addition, by using\nWTM, our method can capture the \u201cone-to-many\u201d\nor \u201cmany-to-one\u201d relations (\u201cone-to-many\u201d means\nthat, in a sentence one opinion word modifies\nseveral opinion targets, and \u201cmany-to-one\u201d means\nseveral opinion words modify one opinion target).\nThus, it\u2019s reasonable to expect that WTM is likely\nto yield better performance than traditional\nmethods for mining associations between opinion\ntargets and opinion words.\nBased on the mined associations, we extract\nopinion targets in a ranking framework. All\nnouns/noun phrases are regarded as opinion target\ncandidates. Then a graph-based algorithm is\nexploited to assign confidences to each candidate,\nin which candidate opinion relevance and\nimportance are incorporated to generate a global\nmeasure. At last, the candidates with higher ranks\nare extracted as opinion targets. Compared with\nmost traditional methods (Hu et al. 2004; Liu et al.,\n2005; Qiu et al., 2011), we don\u2019t extract opinion\ntargets iteratively based on the bootstrapping\nstrategy, such as Double Propagation (Qiu et al.,\n2011), instead all candidates are dynamically\nranked in a global process. Therefore, error\npropagation can be effectively avoided and the\nperformance can be improved.\nThe phone has a colorful and even amazing screen"
                    },
                    {
                        "confidence": 0.555698,
                        "content": "The phone has a colorful and even amazing screen"
                    },
                    {
                        "confidence": 0.9987885,
                        "content": "The main contributions of this paper are as\nfollows.\n1) We formulate the opinion relation\nidentification between opinion targets and\nopinion words as a word alignment task. To\nour best knowledge, none of previous methods\ndeal with this task using monolingual word\nalignment model (in Section 3.1)."
                    },
                    {
                        "confidence": 0.871017210526316,
                        "content": "2) We propose a graph-based algorithm for\nopinion target extraction in which candidate\nopinion relevance and importance are\nincorporated into a unified graph to estimate\ncandidate confidence. Then the candidates\nwith higher confidence scores are extracted as\nopinion targets (in Section 3.2).\n3) We have performed experiments on three\ndatasets in different sizes and languages. The\nexperimental results show that our approach\ncan achieve performance improvement over\nthe traditional methods. (in Section 4).\nThe rest of the paper is organized as follows. In\nthe next section, we will review related work in\nbrief. Section 3 describes our approach in detail.\nThen experimental results will be given in Section\n4. At the same time, we will give some analysis\nabout the results. Finally, we give the conclusion\nand the future work."
                    },
                    {
                        "confidence": 0.999971191176471,
                        "content": "Many studies have focused on the task of opinion\ntarget extraction, such as (Hu et al., 2004; Ding et\nal., 2008; Liu et al., 2006; Popescu et al., 2005;\nWu et al., 2005; Wang et al., 2008; Li et al., 2010;\nSu et al., 2008; Li et al., 2006). In general, the\nexisting approaches can be divided into two main\ncategories: supervised and unsupervised methods.\nIn supervised approaches, the opinion target\nextraction task was usually regarded as a sequence\nlabeling task (Jin et al. 2009; Li et al. 2010; Wu et\nal., 2009; Ma et al. 2010; Zhang et al., 2009). Jin et\nal. (2009) proposed a lexicalized HMM model to\nperform opinion mining. Li et al. (2010) proposed\na Skip-Tree CRF model for opinion target\nextraction. Their methods exploited three\nstructures including linear-chain structure,\nsyntactic structure, and conjunction structure. In\naddition, Wu et al. (2009) utilized a SVM classifier\nto identify relations between opinion targets and\nopinion expressions by leveraging phrase\ndependency parsing. The main limitation of these\nsupervised methods is that labeling training data\nfor each domain is impracticable because of the\ndiversity of the review domains.\nIn unsupervised methods, most approaches\nregarded opinion words as the important indicators\nfor opinion targets (Hu et al., 2004; Popsecu et al.,\n2005; Wang et al., 2008; Qiu et al., 2011; Zhang et\nal., 2010). The basic idea was that reviewers often\nuse the same opinion words when they comment\non the similar opinion targets. The extraction\nprocedure was often a bootstrapping process which\nextracted opinion words and opinion targets\niteratively, depending upon their associations.\nPopsecu et al. (2005) used syntactic patterns to\nextract opinion target candidates. After that they\ncomputed the point-wise mutual information (PMI)\nscore between a candidate and a product category\nto refine the extracted results. Hu et al. (2004)\nexploited an association rule mining algorithm and\nfrequency information to extract frequent explicit\nproduct features. The adjective nearest to the\nfrequent explicit feature was extracted as an\nopinion word. Then the extracted opinion words\nwere used to extract infrequent opinion targets.\nWang et al. (2008) adopted the similar idea, but\ntheir method needed a few seeds to weakly\nsupervise the extraction process. Qiu et al. (2009,\n2011) proposed a Double Propagation method to\nexpand a domain sentiment lexicon and an opinion\ntarget set iteratively. They exploited direct\ndependency relations between words to extract\nopinion targets and opinion words iteratively. The\nmain limitation of Qiu\u2019s method is that the patterns\nbased on dependency parsing tree may introduce\nmany noises for the large corpora (Zhang et al.,\n2010). Meanwhile, Double Propagation is a\nbootstrapping strategy which is a greedy process\nand has the problem of error propagation. Zhang et\nal. (2010) extended Qiu\u2019s method. Besides the\npatterns used in Qiu\u2019s method, they adopted some\nother patterns, such as phrase patterns, sentence\npatterns and \u201cno\u201d pattern, to increase recall. In\naddition they used the HITS (Klernberg et al., 1999)\nalgorithm to compute the feature relevance scores,\nwhich were simply multiplied by the log of feature\nfrequencies to rank the extracted opinion targets. In\nthis way, the precision of result can be improved."
                    },
                    {
                        "confidence": 0.972743705882353,
                        "content": "As mentioned in the first section, our approach for\nopinion target extraction is composed of the\nfollowing two main components:\n1) Mining associations between opinion targets\nand opinion words: Given a collection of\nreviews, we adopt a word-based translation\n1348\nmodel to identify potential opinion relations in\nall sentences, and then the associations\nbetween opinion targets and opinion words are\nestimated.\n2) Candidate confidence estimation: Based on\nthese associations, we exploit a graph-based\nalgorithm to compute the confidence of each\nopinion target candidate. Then the candidates\nwith higher confidence scores are extracted as\nopinion targets."
                    },
                    {
                        "confidence": 0.965742230769231,
                        "content": "targets and opinion words using Word-\nbased Translation Model\nThis component is to identify potential opinion\nrelations in sentences and estimate associations\nbetween opinion targets and opinion words. We\nassume opinion targets and opinion words\nrespectively to be nouns/noun phrases and\nadjectives, which have been widely adopted in\nprevious work (Hu et al., 2004; Ding et al., 2008;\nWang et al., 2008; Qiu et al., 2011). Thus, our aim\nis to find potential opinion relations between\nnouns/noun phrases and adjectives in sentences,\nand calculate the associations between them. As\nmentioned in the first section, we formulate\nopinion relation identification as a word alignment\ntask. We employ the word-based translation model\n(Brown et al. 1993) to perform monolingual word\nalignment, which has been widely used in many\ntasks, such as collocation extraction (Liu et al.,\n2009), question retrieval (Zhou et al., 2011) and so\non. In our method, every sentence is replicated to\ngenerate a parallel corpus, and we apply the\nbilingual word alignment algorithm to the\nmonolingual scenario to align a noun/noun phase\nwith its modifier.\nGiven a sentence with words"
                    },
                    {
                        "confidence": 0.9670345,
                        "content": "maximizing the word alignment probability of the\nsentence as follows."
                    },
                    {
                        "confidence": 0.9891459375,
                        "content": "where means that a noun/noun phrase at\nposition i is aligned with an adjective at position a; .\nIf we directly use this alignment model to our task,\na noun/noun phrase may align with the irrelevant\nwords other than adjectives, like prepositions or\nconjunctions and so on. Thus, in the alignment\nprocedure, we introduce some constrains: 1)\nnouns/noun phrases (adjectives) must be aligned\nwith adjectives (nouns/noun phrases) or null words;\n2) other words can only align with themselves.\nTotally, we employ the following 3 WTMs (IBM\n1~3) to identify opinion relations.\n(2)\nThere are three main factors: t(wj I wa. ) ,\nd (j I aj , n) and n(O, I w,) , which respectively\nmodels different information."
                    },
                    {
                        "confidence": 0.9355759,
                        "content": "information of two words in corpora. If an\nadjective co-occurs with a noun/noun phrase\nfrequently in the reviews, this adjective has high\nassociation with this noun/noun phrase. For\nexample, in reviews of cell phone, \u201cbig\u201d often co-\noccurs with \u201cphone\u2019s size\u201d, so \u201cbig\u201d has high\nassociation with \u201cphone\u2019s size\u201d.\n2) d (j I a j ,1) models word position information,\nwhich describes the probability of a word in\nposition ai aligned with a word in position ."
                    },
                    {
                        "confidence": 0.982540071428572,
                        "content": "describe the ability of a word for \u201cone-to-many\u201d\nalignment. O; denotes the number of words that are\naligned with w; . For example, \u201cIphone4 has\namazing screen and software\u201d. In this sentence,\n\u201camazing\u201d is used to modify two words: \u201cscreen\u201d\nand \u201csoftware\u201d. Soo equals to 2 for \u201camazing\u201d.\nTherefore, in Eq. (2), PBM_, (A I S) only models\nword co-occurrence information. PIBM?2 (A I S)\nadditionally employs word position information.\nBesides these two information, PIBM?3(AIS)\nconsiders the ability of a word for \u201cone-to-many\u201d\nalignment. In the following experiments section,\nwe will discuss the performance difference among\nthese models in detail. Moreover, these models"
                    },
                    {
                        "confidence": 0.99928856,
                        "content": "may capture \u201cone-to-many\u201d or \u201cmany-to-one\u201d\nopinion relations (mentioned in the first section).\nIn our knowledge, it isn\u2019t specifically considered\nby previous methods including adjacent methods\nand syntax-based methods. Meanwhile , the\nalignment results may contain empty-word\nalignments, which means a noun/noun phrase has\nno modifier or an adjective modify nothing in the\nsentence.\nAfter gathering all word pairs from the review\nsentences, we can estimate the translation\nprobabilities between nouns/noun phrases and\nadjectives as follows.\nwhere means the translation\nprobabilities from adjectives to nouns/noun\nphrases. Similarly, we can obtain translation\nprobability p(w, I w,) . Therefore, similar to (Liu\net al. 2009), the association between a noun/noun\nphrase and an adjective is estimated as follows.\nwhere is the harmonic factor to combine these\ntwo translation probabilities. In this paper, we set\nt = 0.5 . For demonstration, we give some\nexamples in Table 1. We can see that our method\nusing WTM can successfully capture associations\nbetween opinion targets and opinion words."
                    },
                    {
                        "confidence": 0.999475279069768,
                        "content": "In this component, we compute the confidence of\neach opinion target candidate and rank them. The\ncandidates with higher confidence are regarded as\nthe opinion targets. We argue that the confidence\nof a candidate is determined by two factors: 1)\nOpinion Relevance; 2) Candidate Importance.\nOpinion Relevance reflects the degree that a\ncandidate is associated to opinion words. If an\nadjective has higher confidence to be an opinion\nword, the noun/noun phrase it modifies will have\nhigher confidence to be an opinion target.\nSimilarly, if a noun/noun phrase has higher\nconfidence to be an opinion target, the adjective\nwhich modifies it will be highly possible to be an\nopinion word. It\u2019s an iterative reinforcement\nprocess, which indicates that existing graph-based\nalgorithms are applicable.\nCandidate Importance reflects the salience of a\ncandidate in the corpus. We assign an importance\nscore to an opinion target candidate f according to\nits score, which is further normalized by the\nsum of scores of all candidates.\nwhere represents a candidate, is the term\nfrequency in the dataset, and is computed by\nusing the Google n-gram corpus1.\nTo model these two factors, a bipartite graph is\nconstructed, the vertices of which include all\nnouns/noun phrases and adjectives. As shown in\nFigure 2, the white vertices represent nouns/noun\nphrases and the gray vertices represent adjectives.\nAn edge between a noun/noun phrase and an\nadjective represents that there is an opinion\nrelation between them. The weight on the edges\nrepresents the association between them, which are\nestimated by using WTM, as shown in Eq. (4).\nTo estimate the confidence of each candidate on\nthis bipartite graph, we exploit a graph-based\nalgorithm, where we use to represent candidate\nconfidence vector, a n x 1 vector. We set the\ncandidate initial confidence with candidate\nimportance score, i.e. Co = S , where S is the\ncandidate initial confidence vector and each item\nin is computed using Eq. (5)."
                    },
                    {
                        "confidence": 0.998614,
                        "content": "Then we compute the candidate confidence by\nusing the following iterative formula."
                    },
                    {
                        "confidence": 0.999736333333333,
                        "content": "where is the candidate confidence vector at\ntime , and is the candidate confidence\nvector at time . is an opinion relevance\nmatrix, a matrix, where is the\nassociated weight between a noun/noun phrase\ni and an adjective .\nTo consider the candidate importance scores, we\nintroduce a reallocate condition: combining the\ncandidate opinion relevance with the candidate\nimportance at each step. Thus we can get the final\nrecursive form of the candidate confidence as\nfollows."
                    },
                    {
                        "confidence": 0.999730666666667,
                        "content": "where is the proportion of candidate\nimportance in the candidate confidence. When\nA, =1 , the candidate confidence is completely\ndetermined by the candidate importance; and when\nA, = , the candidate confidence is determined by\nthe candidate opinion relevance. We will discuss\nits effect in the section of experiments.\nTo solve Eq. (7), we rewrite it as the following\nform."
                    },
                    {
                        "confidence": 0.999207666666667,
                        "content": "where is an identity matrix. To handle the\ninverse of the matrix, we expand the Eq. (8) as a\npower series as following."
                    },
                    {
                        "confidence": 0.983039333333333,
                        "content": "where and is an\napproximate factor. In experiments, we set\nk =100 . Using this equation, we estimate\nconfidences for opinion target candidates. The\ncandidates with higher confidence scores than the\nthreshold will be extracted as the opinion targets."
                    },
                    {
                        "confidence": 0.987542542857143,
                        "content": "In our experiments, we select three real world\ndatasets to evaluate our approach. The first dataset\nis COAE2008 dataset22, which contains Chinese\nreviews of four different products. The detailed\n2 http://ir-china.org.cn/coae2008.html\ninformation can be seen in Table 2. Moreover, to\nevaluate our method comprehensively, we collect a\nlarger collection named by Large, which includes\nthree corpora from three different domains and\ndifferent languages. The detailed statistical\ninformation of this dataset is also shown in Table 2.\nRestaurant is crawled from the Chinese Web site:\nwww.dianping.com. The Hotel and MP3 3 were\nused in (Wang et al., 2011), which are respectively\nclawed from www.tripadvisor.com and\nwww.amazon.com. For each collection, we\nperform random sampling to generate testing\ndataset, which include 6,000 sentences for each\ndomain. Then the opinion targets in Large were\nmanually annotated as the gold standard for\nevaluations. Three annotators are involved in the\nannotation process as follows. First, every\nnoun/noun phrase and its contexts in review\nsentences are extracted. Then two annotators were\nrequired to judge whether every noun/noun phrase\nis opinion target or not. If a conflict happens, a\nthird annotator will make judgment for finial\nresults. The inter-agreement was 0.72. In total, we\nrespectively obtain 1,112, 1,241 and 1,850 opinion\ntargets in Hotel, MP3 and Restaurant. The third\ndataset is Customer Review Datasets 4 (English\nreviews of five products), which was also used in\n(Hu et al., 2004; Qiu et al., 2011). They have\nlabeled opinion targets. The detailed information\ncan be found in (Hu et al., 2004)."
                    },
                    {
                        "confidence": 0.902957,
                        "content": "of the reviews/sentences\nIn experiments, each review is segmented into\nsentences according to punctuations. Then\nsentences are tokenized and the part-of-speech of"
                    },
                    {
                        "confidence": 0.999607571428571,
                        "content": "each word is assigned. Stanford NLP tool5 is used\nto perform POS-tagging and dependency parsing.\nThe method in (Zhu et al., 2009) is used to identify\nnoun phrases. We select precision, recall and F-\nmeasure as the evaluation metrics. We also\nperform a significant test, i.e., a t-test with a\ndefault significant level of 0.05."
                    },
                    {
                        "confidence": 0.999934,
                        "content": "To prove the effectiveness of our method, we\nselect the following state-of-art unsupervised\nmethods as baselines for comparison."
                    },
                    {
                        "confidence": 0.9568461875,
                        "content": "Hu is selected to represent adjacent methods for\nopinion target extraction. And DP and Zhang are\n5 http://nlp.stanford.edu/software/tagger.shtml\nselected to represent syntax-based methods. The\nparameter settings in these three baselines are the\nsame as the original papers. In special, for DP and\nZhang, we used the same patterns for different\nlanguage reviews. The overall performance results\nare shown in Table 3, 4 and 5, respectively, where\n\u201cP\u201d denotes precision, \u201cR\u201d denotes recall and \u201cF\u201d\ndenotes F-measure. Ours denotes full model of our\nmethod, in which we use IBM-3 model for\nidentifying opinion relations between words.\nMoreover, we set = 2 in Eq. (2) and = 0.3 in\nEq. (7). From results, we can make the following\nobservations."
                    },
                    {
                        "confidence": 0.91317183018868,
                        "content": "plus opinion relevance with frequency to\ndetermine the candidate confidence.\n3) In Table 4, the improvement made by Ours on\nRestaurant (Chinese reviews) is larger than\nthat on Hotel and MP3 (English reviews). The\nsame phenomenon can be found when we\ncompare the improvement made by Ours in\nTable 3 (Chinese reviews) with that in Table 5\n(English reviews). We believe that reason is\nthat syntactic patterns used in DP and Zhang\nwere exploited based on English grammar,\nwhich may not be suitable to Chinese language.\nMoreover, another reason is that the\nperformance of parsing on Chinese texts is not\nbetter than that on English texts, which will\nhurt the performance of syntax-based methods\n(DP and Zhang).\n4) Compared the results in Table 3 with the\nresults in Table 4, we can observe that Ours\nobtains larger improvements with the increase\nof the data size. This indicates that our method\nis more effective for opinion target extraction\nthan state-of-art methods, especially for large\ncorpora. When the data size increase, the\nmethods based on syntactic patterns will\nintroduce more noises due to the parsing errors\non informal texts. On the other side, Ours uses\nWTM other than parsing to identify opinion\nrelations between words, and the noises made\nby inaccurate parsing can be avoided. Thus,\nOurs can outperform baselines.\n5) In Table 5, Ours makes comparable results\nwith baselines in Customer Review Datasets,\nalthough there is a little loss in precision in\nsome domains. We believe the reason is that\nthe size of Customer Review Datasets is too\nsmall. As a result, WTM may suffer from data\nsparseness for association estimation.\nNevertheless, the average recall is improved.\nAn Example In Table 6, we show top 10 opinion\ntargets extracted by Hu, DP, Zhang and Ours in\nMP3 of Large. In Hu and DP, since they didn\u2019t\nrank the results, their results are ranked according\nto frequency in this experiment. The errors are\nmarked in bold face. From these examples, we can\nsee Ours extracts more correct opinion targets than\nothers. In special, Ours outperforms Zhang. It\nindicates the effectiveness of our graph-based\nmethod for candidate confidence estimation.\nMoreover, Ours considers candidate importance\nbesides opinion relevance, so some specific\nopinion targets are ranked to the fore, such as\n\u201cvoice recorder\u201d, \u201cfm radio\u201d and \u201clcd screen\u201d."
                    },
                    {
                        "confidence": 0.998484733333333,
                        "content": "In this subsection, we aim to prove the\neffectiveness of our WTM for estimating\nassociations between opinion targets and opinion\nwords. For comparison, we select two baselines for\ncomparison, named as Adjacent and Syntax. These\nbaselines respectively use adjacent rule (Hu et al.\n2004; Wang et al., 2008) and syntactic patterns\n(Qiu et al., 2009) to identify opinion relations in\nsentences. Then the same method (Eq.3 and Eq.4)\nis used to estimate associations between opinion\ntargets and opinion words. At last the same graph-\nbased method (in Section 3.3) is used to extract\nopinion targets. Due to the limitation of the space,\nthe experimental results only on COAE2008\ndataset2 and Large are shown in Figure 3."
                    },
                    {
                        "confidence": 0.905237142857143,
                        "content": "In Figure 3, we observe that Ours using WTM\nmakes significant improvements compared with\n1353\ntwo baselines, both on precision and recall. It\nindicates that WTM is effective for identifying\nopinion relations, which makes the estimation of\nthe associations be more precise."
                    },
                    {
                        "confidence": 0.999845111111111,
                        "content": "In this subsection, we aim to prove the\neffectiveness of our graph-based method for\nopinion target extraction. We design two baselines,\nnamed as WTM_DP and WTM_HITS. Both\nWTM_DP and WTM_HITS use WTM to mine\nassociations between opinion targets and opinion\nwords. Then, WTM_DP uses Double Propagation\nadapted in (Wang et al. 2008; Qiu et al. 2009) to\nextract opinion targets, which only consider the\ncandidate opinion relevance. WTM_HITS uses a\ngraph-based method of Zhang et al. (2010) to\nextract opinion targets, which consider both\ncandidate opinion relevance and frequency. Figure\n4 gives the experimental results on COAE2008\ndataset2 and Large. In Figure 4, we can observe\nthat our graph-based algorithm outperforms not\nonly the method based on Double Propagation, but\nalso the previous graph-based approach."
                    },
                    {
                        "confidence": 0.999967769230769,
                        "content": "In section 3, we use three different WTMs in Eq.\n(2) to identify opinion relations. In this subsection,\nwe make comparison among them. Experimental\nresults on COAE2008 dataset2 and Large are\nshown in Figure 5. Ours_1, Ours_2 and Ours_3\nrespectively denote our method using different\nWTMs (IBM 1~3). From the results in Figure 5,\nwe observe that Ours_2 outperforms Ours_1,\nwhich indicates that word position is useful for\nidentifying opinion relations. Furthermore, Ours_3\noutperforms other models, which indicates that\nconsidering the fertility of a word can produce\nbetter performance."
                    },
                    {
                        "confidence": 0.999635857142857,
                        "content": "In our method, when we employ Eq. (7) to assign\nconfidence score to each candidate,\nA E [0, 1] decides the proportion of candidate\nimportance in our method. Due to the limitation of\nspace, we only show the F-measure of Ours on\nCOAE2008 dataset2 and Large when varying in\nFigure 6.\nIn Figure 6, curves increase firstly, and decrease\nwith the increase of A . The best performance is\nobtained when is around 0.3. It indicates that\ncandidate importance and candidate opinion\nrelevance are both important for candidate\nconfidence estimation. The performance of opinion\ntarget extraction benefits from their combination."
                    },
                    {
                        "confidence": 0.99997645,
                        "content": "This paper proposes a novel graph-based approach\nto extract opinion targets using WTM. Compared\nwith previous adjacent methods and syntax-based\nmethods, by using WTM, our method can capture\nopinion relations more precisely and therefore be\nmore effective for opinion target extraction,\nespecially for large informal Web corpora.\nIn future work, we plan to use other word\nalignment methods, such as discriminative model\n(Liu et al., 2010) for this task. Meanwhile, we will\nadd some syntactic information into WTM to\nconstrain the word alignment process, in order to\nidentify opinion relations between words more\nprecisely. Moreover, we believe that there are\nsome verbs or nouns can be opinion words and\nthey may be helpful for opinion target extraction.\nAnd we think that it\u2019s useful to add some prior\nknowledge of opinion words (sentiment lexicon) in\nour model for estimating candidate opinion\nrelevance."
                    },
                    {
                        "confidence": 0.710289363636364,
                        "content": "The work is supported by the National Natural\nScience Foundation of China (Grant No.\n61070106), the National Basic Research Program\nof China (Grant No. 2012CB316300), Tsinghua\nNational Laboratory for Information Science and\nTechnology (TNList) Cross-discipline Foundation\nand the Opening Project of Beijing Key Laboratory\nof Internet Culture and Digital Dissemination\nResearch (Grant No. 5026035403). We thank the\nanonymous reviewers for their insightful\ncomments."
                    }
                ],
                "affiliation": {
                    "confidence": 0.9885875,
                    "content": "National Laboratory of Pattern Recognition,\nInstitute of Automation, Chinese Academy of Sciences, Beijing, 100190, China"
                },
                "sectionHeader": [
                    {
                        "confidence": 0.984651,
                        "genericHeader": "abstract",
                        "content": "Abstract"
                    },
                    {
                        "confidence": 0.992545,
                        "genericHeader": "introduction",
                        "content": "1 Introduction"
                    },
                    {
                        "confidence": 0.999437,
                        "genericHeader": "related work",
                        "content": "2 Related Work"
                    },
                    {
                        "confidence": 0.980289,
                        "genericHeader": "method",
                        "content": "3 Opinion Target Extraction Using\nWord-Based Translation Model"
                    },
                    {
                        "confidence": 0.999563,
                        "genericHeader": "evaluation",
                        "content": "4 Experiments"
                    },
                    {
                        "confidence": 0.987604,
                        "genericHeader": "conclusions",
                        "content": "5 Conclusions and Future Work"
                    },
                    {
                        "confidence": 0.995601,
                        "genericHeader": "acknowledgments",
                        "content": "Acknowledgements"
                    },
                    {
                        "confidence": 0.942851,
                        "genericHeader": "references",
                        "content": "References"
                    }
                ],
                "tableCaption": [
                    {
                        "confidence": 0.9975005,
                        "content": "Table 1: Examples of associations between opinion\ntargets and opinion words."
                    },
                    {
                        "confidence": 0.986679,
                        "content": "Table 2: Experimental Data Sets, # denotes the size"
                    },
                    {
                        "confidence": 0.992134,
                        "content": "Table 3: Experiments on COAE2008 dataset2"
                    },
                    {
                        "confidence": 0.98999,
                        "content": "Table 4: Experiments on Large"
                    },
                    {
                        "confidence": 0.999743,
                        "content": "Table 5: Experiments on Customer Review Dataset"
                    },
                    {
                        "confidence": 0.958051,
                        "content": "Table 6: Top 10 opinion targets extracted by\ndifferent methods."
                    }
                ],
                "page": [
                    {
                        "confidence": 0.550879,
                        "content": 1346
                    },
                    {
                        "confidence": 0.565863,
                        "content": 1347
                    },
                    {
                        "confidence": 0.464864,
                        "content": 1349
                    },
                    {
                        "confidence": 0.698774,
                        "content": 1352
                    },
                    {
                        "confidence": 0.632154,
                        "content": 1354
                    },
                    {
                        "confidence": 0.777626,
                        "content": 1356
                    }
                ],
                "figureCaption": [
                    {
                        "confidence": 0.990325,
                        "content": "Figure 1: Word-based translation model for\nopinion relation identification"
                    },
                    {
                        "confidence": 0.9637875,
                        "content": "Figure 2: Bipartite graph for modeling relations\nbetween opinion targets and opinion words"
                    },
                    {
                        "confidence": 0.937399,
                        "content": "Figure 3: Experimental comparison among\ndifferent relation identification methods"
                    },
                    {
                        "confidence": 0.885623,
                        "content": "Figure 4: Experimental Comparison between\ndifferent ranking algorithms"
                    },
                    {
                        "confidence": 0.896098,
                        "content": "Figure 5. Experimental results by using different\nword-based translation model.\nFigure 6. Experimental results when varying"
                    }
                ],
                "email": {
                    "confidence": 0.983685,
                    "content": "{kliu, lhxu, jzhao}@nlpr.ia.ac.cn"
                },
                "table": [
                    {
                        "confidence": 0.9759205,
                        "content": "battery life sound software\nwonderful 0.000 0.042 0.000\npoor 0.032 0.000 0.026\nlong 0.025 0.000 0.000"
                    },
                    {
                        "confidence": 0.6769255,
                        "content": "Opinion Target Candidates (nouns/noun phrases)\nOpinion Word Candidates (adjectives)"
                    },
                    {
                        "confidence": 0.990889636363636,
                        "content": "Domain Language #Sentence #Reviews\nCamera Chinese 2075 137\nCar Chinese 4783 157\nLaptop Chinese 1034 56\nPhone Chinese 2644 123\n(a) COAE2008 dataset2\nDomain Language #Sentence #Reviews\nHotel English 1,855,351 185,829\nMP3 English 289,931 30,837\nRestaurant Chinese 1,683,129 395,124\n(b) Large"
                    },
                    {
                        "confidence": 0.969455428571429,
                        "content": "1351\nMethods P Camera F P Car F P Laptop F P Phone F\nR R R R\nHu 0.63 0.65 0.64 0.62 0.58 0.60 0.51 0.67 0.58 0.69 0.60 0.64\nDP 0.71 0.70 0.70 0.72 0.65 0.68 0.58 0.69 0.63 0.78 0.66 0.72\nZhang 0.71 0.78 0.74 0.69 0.68 0.68 0.57 0.80 0.67 0.80 0.71 0.75\nOurs 0.75 0.81 0.78 0.71 0.71 0.71 0.61 0.85 0.71 0.83 0.74 0.78"
                    },
                    {
                        "confidence": 0.999368666666667,
                        "content": "Methods P Hotel F P MP3 F Restaurant\nR R P R F\nHu 0.60 0.65 0.62 0.61 0.68 0.64 0.64 0.69 0.66\nDP 0.67 0.69 0.68 0.69 0.70 0.69 0.74 0.72 0.73\nZhang 0.67 0.76 0.71 0.67 0.77 0.72 0.75 0.79 0.77\nOurs 0.71 0.80 0.75 0.70 0.82 0.76 0.80 0.84 0.82"
                    },
                    {
                        "confidence": 0.999779166666667,
                        "content": "Methods P D1 F P D2 F P D3 F P D4 F P D5 F\nR R R R R\nHu 0.75 0.82 0.78 0.71 0.79 0.75 0.72 0.76 0.74 0.69 0.82 0.75 0.74 0.80 0.77\nDP 0.87 0.81 0.84 0.90 0.81 0.85 0.90 0.86 0.88 0.81 0.84 0.82 0.92 0.86 0.89\nZhang 0.83 0.84 0.83 0.86 0.85 0.85 0.86 0.88 0.87 0.80 0.85 0.83 0.86 0.86 0.86\nOurs 0.84 0.85 0.84 0.87 0.85 0.86 0.88 0.89 0.88 0.81 0.85 0.83 0.89 0.87 0.88"
                    },
                    {
                        "confidence": 0.984244,
                        "content": "Hu quality, thing, drive, feature, battery, sound,\ntime, music, price\nDP quality, battery, software, device, screen, file,\nthing, feature, battery life\nZhang quality, size, battery life, hour, version, function,\nupgrade, number, music\nOurs quality, battery life, voice recorder, video, fm\nradio, battery, file system, screen, lcd screen"
                    }
                ]
            },
            "version": 110505
        },
        {
            "name": "ParsHed",
            "variant": {
                "no": 0,
                "address": {
                    "confidence": 0.728182,
                    "content": "Institute of Automation, Chinese Academy of Sciences, Beijing, 100190,"
                },
                "affiliation": {
                    "confidence": 0.999779,
                    "content": "National Laboratory of Pattern Recognition,"
                },
                "author": [
                    {
                        "confidence": 0.999317,
                        "content": "Kang Liu"
                    },
                    {
                        "confidence": 0.999317,
                        "content": "Liheng Xu"
                    },
                    {
                        "confidence": 0.999317,
                        "content": "Jun Zhao"
                    }
                ],
                "confidence": 0.670979,
                "abstract": {
                    "confidence": 0.998071413793103,
                    "content": "This paper proposes a novel approach to extract opinion targets based on wordbased translation model (WTM). At first, we apply WTM in a monolingual scenario to mine the associations between opinion targets and opinion words. Then, a graphbased algorithm is exploited to extract opinion targets, where candidate opinion relevance estimated from the mined associations, is incorporated with candidate importance to generate a global measure. By using WTM, our method can capture opinion relations more precisely, especially for long-span relations. In particular, compared with previous syntax-based methods, our method can effectively avoid noises from parsing errors when dealing with informal texts in large Web corpora. By using graph-based algorithm, opinion targets are extracted in a global process, which can effectively alleviate the problem of error propagation in traditional methods, such as The experimental results on three real world datasets in different sizes and languages show that our approach is more effective and robust than state-of-art methods."
                },
                "title": {
                    "confidence": 0.997445,
                    "content": "Opinion Target Extraction Using Word-Based Translation Model"
                },
                "email": [
                    {
                        "confidence": 0.969033,
                        "content": "kliu@nlpr.ia.ac.cn"
                    },
                    {
                        "confidence": 0.969033,
                        "content": "lhxu@nlpr.ia.ac.cn"
                    },
                    {
                        "confidence": 0.969033,
                        "content": "jzhao@nlpr.ia.ac.cn"
                    }
                ]
            },
            "version": 110505
        },
        {
            "name": "ParsCit",
            "version": 110505,
            "citationList": {"citation": [
                {
                    "valid": true,
                    "date": 1993,
                    "volume": 19,
                    "rawString": "Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2): 263-311.",
                    "journal": "Computational Linguistics,",
                    "pages": "263--311",
                    "issue": 2,
                    "marker": "Brown, Pietra, Pietra, Mercer, 1993",
                    "contexts": {"context": {
                        "startWordPosition": 2073,
                        "position": 13597,
                        "citStr": "Brown et al. 1993",
                        "content": "ences and estimate associations between opinion targets and opinion words. We assume opinion targets and opinion words respectively to be nouns/noun phrases and adjectives, which have been widely adopted in previous work (Hu et al., 2004; Ding et al., 2008; Wang et al., 2008; Qiu et al., 2011). Thus, our aim is to find potential opinion relations between nouns/noun phrases and adjectives in sentences, and calculate the associations between them. As mentioned in the first section, we formulate opinion relation identification as a word alignment task. We employ the word-based translation model (Brown et al. 1993) to perform monolingual word alignment, which has been widely used in many tasks, such as collocation extraction (Liu et al., 2009), question retrieval (Zhou et al., 2011) and so on. In our method, every sentence is replicated to generate a parallel corpus, and we apply the bilingual word alignment algorithm to the monolingual scenario to align a noun/noun phase with its modifier. Given a sentence with words A =argmax ( |) P A S (1) ( i , a i ) S = {w\u201e w2, ..., wn } , the word alignment A = {(i, a;) I i E [l, n] } can be obtained by maximizing the word alignment probability of the sentence as",
                        "endWordPosition": 2076
                    }},
                    "title": "The Mathematics of Statistical Machine Translation: Parameter Estimation.",
                    "authors": {"author": [
                        "Peter F Brown",
                        "Stephen A Della Pietra",
                        "Vincent J Della Pietra",
                        "Robert L Mercer"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2008,
                    "rawString": "Xiaowen Ding, Bing Liu and Philip S. Yu. 2008. A Holistic Lexicon-Based Approach to Opinion Mining. In Proceedings of WSDM 2008.",
                    "marker": "Ding, Liu, Yu, 2008",
                    "contexts": {"context": [
                        {
                            "startWordPosition": 346,
                            "position": 2365,
                            "citStr": "Ding et al., 2008",
                            "content": "s from these vast amounts of reviews becomes urgent, and has attracted a lot of attentions from many researchers. In opinion mining, one fundamental problem is opinion target extraction. This task is to extract items which opinions are expressed on. In reviews, opinion targets are usually nouns/noun phrases. For example, in the sentence of \u201cThe phone has a colorful and even amazing screen\u201d, \u201cscreen\u201d is an opinion target. In online product reviews, opinion targets often are products or product features, so this task is also named as product feature extraction in previous work (Hu et al., 2004; Ding et al., 2008; Liu et al., 2005; Popescu et al., 2005; Wu et al., 2005; Su et al., 2008). To extract opinion targets, many studies regarded opinion words as strong indicators (Hu et al., 2004; Popescu et al., 2005; Liu et al., 2005; Qiu et al., 2011; Zhang et al., 2010), which is based on the observation that opinion words are usually located around opinion targets, and there are associations between them. Therefore, most pervious methods iteratively extracted opinion targets depending upon the associations between opinion words and opinion targets (Qiu et al., 2011; Zhang et al., 2010). For example, \u201ccolo",
                            "endWordPosition": 349
                        },
                        {
                            "startWordPosition": 1348,
                            "position": 8876,
                            "citStr": "Ding et al., 2008",
                            "content": "asets in different sizes and languages. The experimental results show that our approach can achieve performance improvement over the traditional methods. (in Section 4). The rest of the paper is organized as follows. In the next section, we will review related work in brief. Section 3 describes our approach in detail. Then experimental results will be given in Section 4. At the same time, we will give some analysis about the results. Finally, we give the conclusion and the future work. 2 Related Work Many studies have focused on the task of opinion target extraction, such as (Hu et al., 2004; Ding et al., 2008; Liu et al., 2006; Popescu et al., 2005; Wu et al., 2005; Wang et al., 2008; Li et al., 2010; Su et al., 2008; Li et al., 2006). In general, the existing approaches can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling task (Jin et al. 2009; Li et al. 2010; Wu et al., 2009; Ma et al. 2010; Zhang et al., 2009). Jin et al. (2009) proposed a lexicalized HMM model to perform opinion mining. Li et al. (2010) proposed a Skip-Tree CRF model for opinion target extraction. T",
                            "endWordPosition": 1351
                        },
                        {
                            "startWordPosition": 2017,
                            "position": 13235,
                            "citStr": "Ding et al., 2008",
                            "content": "se associations, we exploit a graph-based algorithm to compute the confidence of each opinion target candidate. Then the candidates with higher confidence scores are extracted as opinion targets. 3.2 Mining associations between opinion targets and opinion words using Wordbased Translation Model This component is to identify potential opinion relations in sentences and estimate associations between opinion targets and opinion words. We assume opinion targets and opinion words respectively to be nouns/noun phrases and adjectives, which have been widely adopted in previous work (Hu et al., 2004; Ding et al., 2008; Wang et al., 2008; Qiu et al., 2011). Thus, our aim is to find potential opinion relations between nouns/noun phrases and adjectives in sentences, and calculate the associations between them. As mentioned in the first section, we formulate opinion relation identification as a word alignment task. We employ the word-based translation model (Brown et al. 1993) to perform monolingual word alignment, which has been widely used in many tasks, such as collocation extraction (Liu et al., 2009), question retrieval (Zhou et al., 2011) and so on. In our method, every sentence is replicated to generate",
                            "endWordPosition": 2020
                        }
                    ]},
                    "title": "A Holistic Lexicon-Based Approach to Opinion Mining.",
                    "booktitle": "In Proceedings of WSDM",
                    "authors": {"author": [
                        "Xiaowen Ding",
                        "Bing Liu",
                        "Philip S Yu"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2010,
                    "rawString": "Xiaowen Ding and Bing Liu. 2010. Resolving Object and Attribute Reference in Opinion Mining. In Proceedings of COLING 2010.",
                    "marker": "Ding, Liu, 2010",
                    "title": "Resolving Object and Attribute Reference in Opinion Mining.",
                    "booktitle": "In Proceedings of COLING",
                    "authors": {"author": [
                        "Xiaowen Ding",
                        "Bing Liu"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2004,
                    "rawString": "Mingqin Hu and Bing Liu. 2004. Mining and Summarizing Customer Reviews. In Proceedings of KDD 2004",
                    "marker": "Hu, Liu, 2004",
                    "title": "Mining and Summarizing Customer Reviews.",
                    "booktitle": "In Proceedings of KDD",
                    "authors": {"author": [
                        "Mingqin Hu",
                        "Bing Liu"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2004,
                    "rawString": "Minqing Hu and Bing Liu. 2004. Mining Opinion Features in Customer Reviews. In Proceedings of AAAI-2004, San Jose, USA, July 2004.",
                    "marker": "Hu, Liu, 2004",
                    "location": "San Jose, USA,",
                    "title": "Mining Opinion Features in Customer Reviews.",
                    "booktitle": "In Proceedings of AAAI-2004,",
                    "authors": {"author": [
                        "Minqing Hu",
                        "Bing Liu"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2009,
                    "rawString": "Wei Jin and Huang Hay Ho. A Novel Lexicalized HMM-based Learning Framework for Web Opinion Mining. In Proceedings of ICML 2009.",
                    "marker": "Jin, Ho, 2009",
                    "title": "A Novel Lexicalized HMM-based Learning Framework for Web Opinion Mining.",
                    "booktitle": "In Proceedings of ICML",
                    "authors": {"author": [
                        "Wei Jin",
                        "Huang Hay Ho"
                    ]}
                },
                {
                    "valid": true,
                    "date": 1999,
                    "volume": 46,
                    "rawString": "Jon Klernberg. 1999. Authoritative Sources in Hyperlinked Environment. Journal of the ACM 46(5): 604-632",
                    "journal": "Journal of the ACM",
                    "pages": "604--632",
                    "issue": 5,
                    "marker": "Klernberg, 1999",
                    "title": "Authoritative Sources in Hyperlinked Environment.",
                    "authors": {"author": "Jon Klernberg"}
                },
                {
                    "valid": true,
                    "date": 2006,
                    "rawString": "Zhuang Li, Feng Jing, Xiao-yan Zhu. 2006. Movie Review Mining and Summarization. In Proceedings of CIKM 2006",
                    "marker": "Li, Jing, Zhu, 2006",
                    "contexts": {"context": {
                        "startWordPosition": 1376,
                        "position": 9004,
                        "citStr": "Li et al., 2006",
                        "content": "the traditional methods. (in Section 4). The rest of the paper is organized as follows. In the next section, we will review related work in brief. Section 3 describes our approach in detail. Then experimental results will be given in Section 4. At the same time, we will give some analysis about the results. Finally, we give the conclusion and the future work. 2 Related Work Many studies have focused on the task of opinion target extraction, such as (Hu et al., 2004; Ding et al., 2008; Liu et al., 2006; Popescu et al., 2005; Wu et al., 2005; Wang et al., 2008; Li et al., 2010; Su et al., 2008; Li et al., 2006). In general, the existing approaches can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling task (Jin et al. 2009; Li et al. 2010; Wu et al., 2009; Ma et al. 2010; Zhang et al., 2009). Jin et al. (2009) proposed a lexicalized HMM model to perform opinion mining. Li et al. (2010) proposed a Skip-Tree CRF model for opinion target extraction. Their methods exploited three structures including linear-chain structure, syntactic structure, and conjunction structure. In add",
                        "endWordPosition": 1379
                    }},
                    "title": "Movie Review Mining and Summarization.",
                    "booktitle": "In Proceedings of CIKM",
                    "authors": {"author": [
                        "Zhuang Li",
                        "Feng Jing",
                        "Xiao-yan Zhu"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2010,
                    "rawString": "Fangtao Li, Chao Han, Minlie Huang and Xiaoyan Zhu. 2010. Structure-Aware Review Mining and Summarization. In Proceedings of COLING 2010.",
                    "marker": "Li, Han, Huang, Zhu, 2010",
                    "contexts": {"context": {
                        "startWordPosition": 1368,
                        "position": 8969,
                        "citStr": "Li et al., 2010",
                        "content": "ieve performance improvement over the traditional methods. (in Section 4). The rest of the paper is organized as follows. In the next section, we will review related work in brief. Section 3 describes our approach in detail. Then experimental results will be given in Section 4. At the same time, we will give some analysis about the results. Finally, we give the conclusion and the future work. 2 Related Work Many studies have focused on the task of opinion target extraction, such as (Hu et al., 2004; Ding et al., 2008; Liu et al., 2006; Popescu et al., 2005; Wu et al., 2005; Wang et al., 2008; Li et al., 2010; Su et al., 2008; Li et al., 2006). In general, the existing approaches can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling task (Jin et al. 2009; Li et al. 2010; Wu et al., 2009; Ma et al. 2010; Zhang et al., 2009). Jin et al. (2009) proposed a lexicalized HMM model to perform opinion mining. Li et al. (2010) proposed a Skip-Tree CRF model for opinion target extraction. Their methods exploited three structures including linear-chain structure, syntactic structure",
                        "endWordPosition": 1371
                    }},
                    "title": "Structure-Aware Review Mining and Summarization.",
                    "booktitle": "In Proceedings of COLING",
                    "authors": {"author": [
                        "Fangtao Li",
                        "Chao Han",
                        "Minlie Huang",
                        "Xiaoyan Zhu"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2009,
                    "rawString": "Zhichao Li, Min Zhang, Shaoping Ma, Bo Zhou, Yu Sun. Automatic Extraction for Product Feature Words from Comments on the Web. In Proceedings of AIRS 2009.",
                    "marker": "Li, Zhang, Ma, Zhou, Sun, 2009",
                    "title": "Automatic Extraction for Product Feature Words from Comments on the Web. In",
                    "booktitle": "Proceedings of AIRS",
                    "authors": {"author": [
                        "Zhichao Li",
                        "Min Zhang",
                        "Shaoping Ma",
                        "Bo Zhou",
                        "Yu Sun"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2005,
                    "rawString": "Bing Liu, Hu Mingqing and Cheng Junsheng. 2005. Opinion Observer: Analyzing and Comparing Opinions on the Web. In Proceedings of WWW 2005",
                    "marker": "Liu, 2005",
                    "title": "Hu Mingqing and Cheng Junsheng.",
                    "booktitle": "Proceedings of WWW",
                    "authors": {"author": "Bing Liu"}
                },
                {
                    "valid": true,
                    "date": 2006,
                    "rawString": "Bing Liu. 2006. Web Data Mining: Exploring Hyperlinks, contents and usage data. Springer, 2006",
                    "marker": "Liu, 2006",
                    "publisher": "Springer,",
                    "title": "Web Data Mining: Exploring Hyperlinks, contents and usage data.",
                    "authors": {"author": "Bing Liu"}
                },
                {
                    "valid": true,
                    "date": 2010,
                    "note": "second edition,",
                    "rawString": "Bing Liu. 2010. Sentiment analysis and subjectivity. Handbook of Natural Language Processing, second edition, 2010.",
                    "marker": "Liu, 2010",
                    "title": "Sentiment analysis and subjectivity.",
                    "booktitle": "Handbook of Natural Language Processing,",
                    "authors": {"author": "Bing Liu"}
                },
                {
                    "valid": true,
                    "date": 2010,
                    "volume": 36,
                    "rawString": "Yang Liu, Qun Liu, and Shouxun Lin. 2010. Discriminative word alignment by linear modeling. Computational Linguistics, 36(3):303\u2013339.",
                    "journal": "Computational Linguistics,",
                    "issue": 3,
                    "marker": "Liu, Liu, Lin, 2010",
                    "contexts": {"context": {
                        "startWordPosition": 5267,
                        "position": 33587,
                        "citStr": "Liu et al., 2010",
                        "content": "m their combination. Figure 5. Experimental results by using different word-based translation model. Figure 6. Experimental results when varying 1354 5 Conclusions and Future Work This paper proposes a novel graph-based approach to extract opinion targets using WTM. Compared with previous adjacent methods and syntax-based methods, by using WTM, our method can capture opinion relations more precisely and therefore be more effective for opinion target extraction, especially for large informal Web corpora. In future work, we plan to use other word alignment methods, such as discriminative model (Liu et al., 2010) for this task. Meanwhile, we will add some syntactic information into WTM to constrain the word alignment process, in order to identify opinion relations between words more precisely. Moreover, we believe that there are some verbs or nouns can be opinion words and they may be helpful for opinion target extraction. And we think that it\u2019s useful to add some prior knowledge of opinion words (sentiment lexicon) in our model for estimating candidate opinion relevance. Acknowledgements The work is supported by the National Natural Science Foundation of China (Grant No. 61070106), the National Basic",
                        "endWordPosition": 5270
                    }},
                    "title": "Discriminative word alignment by linear modeling.",
                    "authors": {"author": [
                        "Yang Liu",
                        "Qun Liu",
                        "Shouxun Lin"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2009,
                    "rawString": "Zhanyi Liu, Haifeng Wang, Hua Wu and Sheng Li. 2009. Collocation Extraction Using Monolingual Word Alignment Model. In Proceedings of EMNLP 2009.",
                    "marker": "Liu, Wang, Wu, Li, 2009",
                    "contexts": {"context": [
                        {
                            "startWordPosition": 915,
                            "position": 6061,
                            "citStr": "Liu et al., 2009",
                            "content": "its corresponding modifier through monolingual word alignment. For example in Figure 1, the opinion words \u201ccolorful\u201d and \u201camazing\u201d are aligned with the target \u201cscreen\u201d through word alignment. To this end, we use WTM to perform monolingual word alignment for mining associations between opinion targets and opinion words. In this process, several factors, such as word co-occurrence frequencies, word positions etc., can be considered globally. Compared with adjacent methods, WTM doesn\u2019t identify opinion relations between words in a given window, so long-span relations can be effectively captured (Liu et al., 2009). Compared with syntax-based methods, without using parsing, WTM can effectively avoid errors from parsing informal texts. So it will be more robust. In addition, by using WTM, our method can capture the \u201cone-to-many\u201d or \u201cmany-to-one\u201d relations (\u201cone-to-many\u201d means that, in a sentence one opinion word modifies several opinion targets, and \u201cmany-to-one\u201d means several opinion words modify one opinion target). Thus, it\u2019s reasonable to expect that WTM is likely to yield better performance than traditional methods for mining associations between opinion targets and opinion words. Based on the mined",
                            "endWordPosition": 918
                        },
                        {
                            "startWordPosition": 2094,
                            "position": 13728,
                            "citStr": "Liu et al., 2009",
                            "content": "to be nouns/noun phrases and adjectives, which have been widely adopted in previous work (Hu et al., 2004; Ding et al., 2008; Wang et al., 2008; Qiu et al., 2011). Thus, our aim is to find potential opinion relations between nouns/noun phrases and adjectives in sentences, and calculate the associations between them. As mentioned in the first section, we formulate opinion relation identification as a word alignment task. We employ the word-based translation model (Brown et al. 1993) to perform monolingual word alignment, which has been widely used in many tasks, such as collocation extraction (Liu et al., 2009), question retrieval (Zhou et al., 2011) and so on. In our method, every sentence is replicated to generate a parallel corpus, and we apply the bilingual word alignment algorithm to the monolingual scenario to align a noun/noun phase with its modifier. Given a sentence with words A =argmax ( |) P A S (1) ( i , a i ) S = {w\u201e w2, ..., wn } , the word alignment A = {(i, a;) I i E [l, n] } can be obtained by maximizing the word alignment probability of the sentence as follows. ˆ A where means that a noun/noun phrase at position i is aligned with an adjective at position a; . If we directly use thi",
                            "endWordPosition": 2097
                        },
                        {
                            "startWordPosition": 2610,
                            "position": 16849,
                            "citStr": "Liu et al. 2009",
                            "content": "edge, it isn\u2019t specifically considered by previous methods including adjacent methods and syntax-based methods. Meanwhile , the alignment results may contain empty-word alignments, which means a noun/noun phrase has no modifier or an adjective modify nothing in the sentence. After gathering all word pairs from the review sentences, we can estimate the translation probabilities between nouns/noun phrases and adjectives as follows. where means the translation probabilities from adjectives to nouns/noun phrases. Similarly, we can obtain translation probability p(w, I w,) . Therefore, similar to (Liu et al. 2009), the association between a noun/noun phrase and an adjective is estimated as follows. where is the harmonic factor to combine these two translation probabilities. In this paper, we set t = 0.5 . For demonstration, we give some examples in Table 1. We can see that our method using WTM can successfully capture associations between opinion targets and opinion words. battery life sound software wonderful 0.000 0.042 0.000 poor 0.032 0.000 0.026 long 0.025 0.000 0.000 Table 1: Examples of associations between opinion targets and opinion words. 3.3 Candidate Confidence Estimation In this component,",
                            "endWordPosition": 2613
                        }
                    ]},
                    "title": "Collocation Extraction Using Monolingual Word Alignment Model.",
                    "booktitle": "In Proceedings of EMNLP",
                    "authors": {"author": [
                        "Zhanyi Liu",
                        "Haifeng Wang",
                        "Hua Wu",
                        "Sheng Li"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2010,
                    "rawString": "Tengfei Ma and Xiaojun Wan. 2010. Opinion Target Extraction in Chinese News Comments. In Proceedings of COLING 2010.",
                    "marker": "Ma, Wan, 2010",
                    "title": "Opinion Target Extraction in Chinese News Comments.",
                    "booktitle": "In Proceedings of COLING",
                    "authors": {"author": [
                        "Tengfei Ma",
                        "Xiaojun Wan"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2005,
                    "rawString": "Popescu, Ana-Maria and Oren, Etzioni. 2005. Extracting produt fedatures and opinions from reviews. In Proceedings of EMNLP 2005",
                    "marker": "Popescu, Oren, 2005",
                    "title": "Extracting produt fedatures and opinions from reviews.",
                    "booktitle": "In Proceedings of EMNLP",
                    "authors": {"author": [
                        "Ana-Maria Popescu",
                        "Etzioni Oren"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2009,
                    "rawString": "Guang Qiu, Bing Liu., Jiajun Bu and Chun Che. 2009. Expanding Domain Sentiment Lexicon through Double Popagation. In Proceedings of IJCAI 2009",
                    "marker": "Qiu, Liu, Bu, Che, 2009",
                    "contexts": {"context": [
                        {
                            "startWordPosition": 625,
                            "position": 4131,
                            "citStr": "Qiu et al., 2009",
                            "content": "his end, most previous methods (Hu et al., 2004; Ding et al., 2004; Wang et al., 2008), named as adjacent methods, employed the adjacent rule, where an opinion target was regarded to have opinion relations with the surrounding opinion words in a given window. However, because of the limitation of window size, opinion relations cannot be captured precisely, especially for long-span relations, which would hurt estimating associations between opinion targets and opinion words. To resolve this problem, several studies exploited syntactic information such as dependency trees (Popescu et al., 2005; Qiu et al., 2009; Qiu et al., 2011; Wu et al., 2009; Zhang et al., 2010). If the syntactic relation between an opinion word and an opinion target satisfied a designed pattern, then there was an opinion relation between them. Experiments consistently reported that syntaxbased methods could yield better performance than adjacent methods for small or medium corpora (Zhang et al., 2010). The performance of syntaxbased methods heavily depends on the parsing performance. However, online reviews are often informal texts (including grammar mistakes, typos, improper punctuations etc.). As a result, parsing may generat",
                            "endWordPosition": 628
                        },
                        {
                            "startWordPosition": 1695,
                            "position": 11089,
                            "citStr": "Qiu et al. (2009",
                            "content": "target candidates. After that they computed the point-wise mutual information (PMI) score between a candidate and a product category to refine the extracted results. Hu et al. (2004) exploited an association rule mining algorithm and frequency information to extract frequent explicit product features. The adjective nearest to the frequent explicit feature was extracted as an opinion word. Then the extracted opinion words were used to extract infrequent opinion targets. Wang et al. (2008) adopted the similar idea, but their method needed a few seeds to weakly supervise the extraction process. Qiu et al. (2009, 2011) proposed a Double Propagation method to expand a domain sentiment lexicon and an opinion target set iteratively. They exploited direct dependency relations between words to extract opinion targets and opinion words iteratively. The main limitation of Qiu\u2019s method is that the patterns based on dependency parsing tree may introduce many noises for the large corpora (Zhang et al., 2010). Meanwhile, Double Propagation is a bootstrapping strategy which is a greedy process and has the problem of error propagation. Zhang et al. (2010) extended Qiu\u2019s method. Besides the patterns used in Qiu\u2019s",
                            "endWordPosition": 1698
                        },
                        {
                            "startWordPosition": 4671,
                            "position": 29674,
                            "citStr": "Qiu et al., 2009",
                            "content": "ethod for candidate confidence estimation. Moreover, Ours considers candidate importance besides opinion relevance, so some specific opinion targets are ranked to the fore, such as \u201cvoice recorder\u201d, \u201cfm radio\u201d and \u201clcd screen\u201d. 4.3 Effect of Word-based Translation Model In this subsection, we aim to prove the effectiveness of our WTM for estimating associations between opinion targets and opinion words. For comparison, we select two baselines for comparison, named as Adjacent and Syntax. These baselines respectively use adjacent rule (Hu et al. 2004; Wang et al., 2008) and syntactic patterns (Qiu et al., 2009) to identify opinion relations in sentences. Then the same method (Eq.3 and Eq.4) is used to estimate associations between opinion targets and opinion words. At last the same graphbased method (in Section 3.3) is used to extract opinion targets. Due to the limitation of the space, the experimental results only on COAE2008 dataset2 and Large are shown in Figure 3. Figure 3: Experimental comparison among different relation identification methods Hu quality, thing, drive, feature, battery, sound, time, music, price DP quality, battery, software, device, screen, file, thing, feature, battery life",
                            "endWordPosition": 4674
                        },
                        {
                            "startWordPosition": 4902,
                            "position": 31179,
                            "citStr": "Qiu et al. 2009",
                            "content": "WTM makes significant improvements compared with 1353 two baselines, both on precision and recall. It indicates that WTM is effective for identifying opinion relations, which makes the estimation of the associations be more precise. 4.4 Effect of Our Graph-based Method In this subsection, we aim to prove the effectiveness of our graph-based method for opinion target extraction. We design two baselines, named as WTM_DP and WTM_HITS. Both WTM_DP and WTM_HITS use WTM to mine associations between opinion targets and opinion words. Then, WTM_DP uses Double Propagation adapted in (Wang et al. 2008; Qiu et al. 2009) to extract opinion targets, which only consider the candidate opinion relevance. WTM_HITS uses a graph-based method of Zhang et al. (2010) to extract opinion targets, which consider both candidate opinion relevance and frequency. Figure 4 gives the experimental results on COAE2008 dataset2 and Large. In Figure 4, we can observe that our graph-based algorithm outperforms not only the method based on Double Propagation, but also the previous graph-based approach. Figure 4: Experimental Comparison between different ranking algorithms 4.5 Parameter Influences 4.5.1 Effect of Different WTMs In sec",
                            "endWordPosition": 4905
                        }
                    ]},
                    "title": "Expanding Domain Sentiment Lexicon through Double Popagation.",
                    "booktitle": "In Proceedings of IJCAI",
                    "authors": {"author": [
                        "Guang Qiu",
                        "Bing Liu",
                        "Jiajun Bu",
                        "Chun Che"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2011,
                    "rawString": "Guang Qiu, Bing Liu, Jiajun Bu and Chun Chen. 2011. Opinion Word Expansion and Target Extraction 1355",
                    "pages": 1355,
                    "marker": "Qiu, Liu, Bu, Chen, 2011",
                    "contexts": {"context": [
                        {
                            "startWordPosition": 390,
                            "position": 2601,
                            "citStr": "Qiu et al., 2011",
                            "content": "xpressed on. In reviews, opinion targets are usually nouns/noun phrases. For example, in the sentence of \u201cThe phone has a colorful and even amazing screen\u201d, \u201cscreen\u201d is an opinion target. In online product reviews, opinion targets often are products or product features, so this task is also named as product feature extraction in previous work (Hu et al., 2004; Ding et al., 2008; Liu et al., 2005; Popescu et al., 2005; Wu et al., 2005; Su et al., 2008). To extract opinion targets, many studies regarded opinion words as strong indicators (Hu et al., 2004; Popescu et al., 2005; Liu et al., 2005; Qiu et al., 2011; Zhang et al., 2010), which is based on the observation that opinion words are usually located around opinion targets, and there are associations between them. Therefore, most pervious methods iteratively extracted opinion targets depending upon the associations between opinion words and opinion targets (Qiu et al., 2011; Zhang et al., 2010). For example, \u201ccolorful\u201d and \u201camazing\u201d is usually used to modify \u201cscreen\u201d in reviews about cell phone, so there are strong associations between them. If \u201ccolorful\u201d and \u201camazing\u201d had been known to be opinion words, \u201cscreen\u201d is likely to be an opinion targe",
                            "endWordPosition": 393
                        },
                        {
                            "startWordPosition": 629,
                            "position": 4149,
                            "citStr": "Qiu et al., 2011",
                            "content": "ious methods (Hu et al., 2004; Ding et al., 2004; Wang et al., 2008), named as adjacent methods, employed the adjacent rule, where an opinion target was regarded to have opinion relations with the surrounding opinion words in a given window. However, because of the limitation of window size, opinion relations cannot be captured precisely, especially for long-span relations, which would hurt estimating associations between opinion targets and opinion words. To resolve this problem, several studies exploited syntactic information such as dependency trees (Popescu et al., 2005; Qiu et al., 2009; Qiu et al., 2011; Wu et al., 2009; Zhang et al., 2010). If the syntactic relation between an opinion word and an opinion target satisfied a designed pattern, then there was an opinion relation between them. Experiments consistently reported that syntaxbased methods could yield better performance than adjacent methods for small or medium corpora (Zhang et al., 2010). The performance of syntaxbased methods heavily depends on the parsing performance. However, online reviews are often informal texts (including grammar mistakes, typos, improper punctuations etc.). As a result, parsing may generate many mistakes. T",
                            "endWordPosition": 632
                        },
                        {
                            "startWordPosition": 1076,
                            "position": 7142,
                            "citStr": "Qiu et al., 2011",
                            "content": "yield better performance than traditional methods for mining associations between opinion targets and opinion words. Based on the mined associations, we extract opinion targets in a ranking framework. All nouns/noun phrases are regarded as opinion target candidates. Then a graph-based algorithm is exploited to assign confidences to each candidate, in which candidate opinion relevance and importance are incorporated to generate a global measure. At last, the candidates with higher ranks are extracted as opinion targets. Compared with most traditional methods (Hu et al. 2004; Liu et al., 2005; Qiu et al., 2011), we don\u2019t extract opinion targets iteratively based on the bootstrapping strategy, such as Double Propagation (Qiu et al., 2011), instead all candidates are dynamically ranked in a global process. Therefore, error propagation can be effectively avoided and the performance can be improved. The phone has a colorful and even amazing screen Translation The phone has a colorful and even amazing screen Figure 1: Word-based translation model for opinion relation identification The main contributions of this paper are as follows. 1) We formulate the opinion relation identification between opinion tar",
                            "endWordPosition": 1079
                        },
                        {
                            "startWordPosition": 1547,
                            "position": 10112,
                            "citStr": "Qiu et al., 2011",
                            "content": "ed three structures including linear-chain structure, syntactic structure, and conjunction structure. In addition, Wu et al. (2009) utilized a SVM classifier to identify relations between opinion targets and opinion expressions by leveraging phrase dependency parsing. The main limitation of these supervised methods is that labeling training data for each domain is impracticable because of the diversity of the review domains. In unsupervised methods, most approaches regarded opinion words as the important indicators for opinion targets (Hu et al., 2004; Popsecu et al., 2005; Wang et al., 2008; Qiu et al., 2011; Zhang et al., 2010). The basic idea was that reviewers often use the same opinion words when they comment on the similar opinion targets. The extraction procedure was often a bootstrapping process which extracted opinion words and opinion targets iteratively, depending upon their associations. Popsecu et al. (2005) used syntactic patterns to extract opinion target candidates. After that they computed the point-wise mutual information (PMI) score between a candidate and a product category to refine the extracted results. Hu et al. (2004) exploited an association rule mining algorithm and freq",
                            "endWordPosition": 1550
                        },
                        {
                            "startWordPosition": 2025,
                            "position": 13273,
                            "citStr": "Qiu et al., 2011",
                            "content": "sed algorithm to compute the confidence of each opinion target candidate. Then the candidates with higher confidence scores are extracted as opinion targets. 3.2 Mining associations between opinion targets and opinion words using Wordbased Translation Model This component is to identify potential opinion relations in sentences and estimate associations between opinion targets and opinion words. We assume opinion targets and opinion words respectively to be nouns/noun phrases and adjectives, which have been widely adopted in previous work (Hu et al., 2004; Ding et al., 2008; Wang et al., 2008; Qiu et al., 2011). Thus, our aim is to find potential opinion relations between nouns/noun phrases and adjectives in sentences, and calculate the associations between them. As mentioned in the first section, we formulate opinion relation identification as a word alignment task. We employ the word-based translation model (Brown et al. 1993) to perform monolingual word alignment, which has been widely used in many tasks, such as collocation extraction (Liu et al., 2009), question retrieval (Zhou et al., 2011) and so on. In our method, every sentence is replicated to generate a parallel corpus, and we apply the b",
                            "endWordPosition": 2028
                        },
                        {
                            "startWordPosition": 3513,
                            "position": 22620,
                            "citStr": "Qiu et al., 2011",
                            "content": "evaluations. Three annotators are involved in the annotation process as follows. First, every noun/noun phrase and its contexts in review sentences are extracted. Then two annotators were required to judge whether every noun/noun phrase is opinion target or not. If a conflict happens, a third annotator will make judgment for finial results. The inter-agreement was 0.72. In total, we respectively obtain 1,112, 1,241 and 1,850 opinion targets in Hotel, MP3 and Restaurant. The third dataset is Customer Review Datasets 4 (English reviews of five products), which was also used in (Hu et al., 2004; Qiu et al., 2011). They have labeled opinion targets. The detailed information can be found in (Hu et al., 2004). Domain Language #Sentence #Reviews Camera Chinese 2075 137 Car Chinese 4783 157 Laptop Chinese 1034 56 Phone Chinese 2644 123 (a) COAE2008 dataset2 Domain Language #Sentence #Reviews Hotel English 1,855,351 185,829 MP3 English 289,931 30,837 Restaurant Chinese 1,683,129 395,124 (b) Large Table 2: Experimental Data Sets, # denotes the size of the reviews/sentences In experiments, each review is segmented into sentences according to punctuations. Then sentences are tokenized and the part-of-speech of",
                            "endWordPosition": 3516
                        },
                        {
                            "startWordPosition": 3940,
                            "position": 25038,
                            "citStr": "Qiu et al., 2011",
                            "content": "ool5 is used to perform POS-tagging and dependency parsing. The method in (Zhu et al., 2009) is used to identify noun phrases. We select precision, recall and Fmeasure as the evaluation metrics. We also perform a significant test, i.e., a t-test with a default significant level of 0.05. 4.2 Our Methods vs. State-of-art Methods To prove the effectiveness of our method, we select the following state-of-art unsupervised methods as baselines for comparison. 1) Hu is the method described in (Hu et al., 2004), which extracted opinion targets by using adjacent rule. 2) DP is the method described in (Qiu et al., 2011), which used Double Propagation algorithm to extract opinion targets depending on syntactic relations between words. 3) Zhang is the method described in (Zhang et al., 2010), which is an extension of DP. They extracted opinion targets candidates using syntactic patterns and other specific patterns. Then HITS (Kleinberg 1999) algorithm combined with candidate frequency is employed to rank the results for opinion target extraction. Hu is selected to represent adjacent methods for opinion target extraction. And DP and Zhang are 5 http://nlp.stanford.edu/software/tagger.shtml selected to represent",
                            "endWordPosition": 3943
                        }
                    ]},
                    "booktitle": "Opinion Word Expansion and Target Extraction",
                    "authors": {"author": [
                        "Guang Qiu",
                        "Bing Liu",
                        "Jiajun Bu",
                        "Chun Chen"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2011,
                    "volume": 37,
                    "rawString": "through Double Propagation. Computational Linguistics, March 2011, Vol. 37, No. 1: 9.27",
                    "pages": "9--27",
                    "marker": "Double, 2011",
                    "title": "Propagation. Computational Linguistics,",
                    "authors": {"author": "through Double"}
                },
                {
                    "valid": true,
                    "date": 2008,
                    "rawString": "Qi Su, Xinying Xu., Honglei Guo, Zhili Guo, Xian Wu, Xiaoxun Zhang, Bin Swen and Zhong Su. 2008. Hidden Sentiment Association in Chinese Web Opinion Mining. In Proceedings of WWW 2008",
                    "marker": "Su, 2008",
                    "title": "Xinying Xu., Honglei Guo, Zhili Guo, Xian Wu, Xiaoxun Zhang, Bin Swen and Zhong Su.",
                    "booktitle": "In Proceedings of WWW",
                    "authors": {"author": "Qi Su"}
                },
                {
                    "valid": true,
                    "date": 2008,
                    "rawString": "Bo Wang, Houfeng Wang. Bootstrapping both Product Features and Opinion Words from Chinese Customer Reviews with Cross-Inducing. In Proceedings of IJCNLP 2008.",
                    "marker": "Wang, 2008",
                    "title": "Houfeng Wang. Bootstrapping both Product Features and Opinion Words from Chinese Customer Reviews with Cross-Inducing.",
                    "booktitle": "In Proceedings of IJCNLP",
                    "authors": {"author": "Bo Wang"}
                },
                {
                    "valid": true,
                    "date": 2011,
                    "rawString": "Hongning Wang, Yue Lu and Chengxiang Zhai. 2011. Latent Aspect Rating Analysis without Aspect Keyword Supervision. In Proceedings of KDD 2011.",
                    "marker": "Wang, Lu, Zhai, 2011",
                    "contexts": {"context": {
                        "startWordPosition": 3375,
                        "position": 21719,
                        "citStr": "Wang et al., 2011",
                        "content": "three real world datasets to evaluate our approach. The first dataset is COAE2008 dataset22, which contains Chinese reviews of four different products. The detailed 2 http://ir-china.org.cn/coae2008.html information can be seen in Table 2. Moreover, to evaluate our method comprehensively, we collect a larger collection named by Large, which includes three corpora from three different domains and different languages. The detailed statistical information of this dataset is also shown in Table 2. Restaurant is crawled from the Chinese Web site: www.dianping.com. The Hotel and MP3 3 were used in (Wang et al., 2011), which are respectively clawed from www.tripadvisor.com and www.amazon.com. For each collection, we perform random sampling to generate testing dataset, which include 6,000 sentences for each domain. Then the opinion targets in Large were manually annotated as the gold standard for evaluations. Three annotators are involved in the annotation process as follows. First, every noun/noun phrase and its contexts in review sentences are extracted. Then two annotators were required to judge whether every noun/noun phrase is opinion target or not. If a conflict happens, a third annotator will make ju",
                        "endWordPosition": 3378
                    }},
                    "title": "Latent Aspect Rating Analysis without Aspect Keyword Supervision.",
                    "booktitle": "In Proceedings of KDD",
                    "authors": {"author": [
                        "Hongning Wang",
                        "Yue Lu",
                        "Chengxiang Zhai"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2009,
                    "rawString": "Yuanbin Wu, Qi Zhang, Xuangjing Huang and Lide Wu, 2009, Phrase Dependency Parsing For Opinion Mining, In Proceedings of EMNLP 2009",
                    "marker": "Wu, Zhang, Huang, Wu, 2009",
                    "contexts": {"context": [
                        {
                            "startWordPosition": 530,
                            "position": 3509,
                            "citStr": "Wu et al., 2009",
                            "content": "inion targets (Qiu et al., 2011; Zhang et al., 2010). For example, \u201ccolorful\u201d and \u201camazing\u201d is usually used to modify \u201cscreen\u201d in reviews about cell phone, so there are strong associations between them. If \u201ccolorful\u201d and \u201camazing\u201d had been known to be opinion words, \u201cscreen\u201d is likely to be an opinion target in this domain. In addition, the extracted opinion targets can be used to expand more opinion words according to their associations. It\u2019s a mutual reinforcement procedure. Therefore, mining associations between opinion targets and opinion words is a key for opinion 1346 target extraction (Wu et al., 2009). To this end, most previous methods (Hu et al., 2004; Ding et al., 2004; Wang et al., 2008), named as adjacent methods, employed the adjacent rule, where an opinion target was regarded to have opinion relations with the surrounding opinion words in a given window. However, because of the limitation of window size, opinion relations cannot be captured precisely, especially for long-span relations, which would hurt estimating associations between opinion targets and opinion words. To resolve this problem, several studies exploited syntactic information such as dependency trees (Popescu et al.,",
                            "endWordPosition": 533
                        },
                        {
                            "startWordPosition": 1420,
                            "position": 9279,
                            "citStr": "Wu et al., 2009",
                            "content": "some analysis about the results. Finally, we give the conclusion and the future work. 2 Related Work Many studies have focused on the task of opinion target extraction, such as (Hu et al., 2004; Ding et al., 2008; Liu et al., 2006; Popescu et al., 2005; Wu et al., 2005; Wang et al., 2008; Li et al., 2010; Su et al., 2008; Li et al., 2006). In general, the existing approaches can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling task (Jin et al. 2009; Li et al. 2010; Wu et al., 2009; Ma et al. 2010; Zhang et al., 2009). Jin et al. (2009) proposed a lexicalized HMM model to perform opinion mining. Li et al. (2010) proposed a Skip-Tree CRF model for opinion target extraction. Their methods exploited three structures including linear-chain structure, syntactic structure, and conjunction structure. In addition, Wu et al. (2009) utilized a SVM classifier to identify relations between opinion targets and opinion expressions by leveraging phrase dependency parsing. The main limitation of these supervised methods is that labeling training data for each domain is impracticable be",
                            "endWordPosition": 1423
                        }
                    ]},
                    "title": "Phrase Dependency Parsing For Opinion Mining,",
                    "booktitle": "In Proceedings of EMNLP",
                    "authors": {"author": [
                        "Yuanbin Wu",
                        "Qi Zhang",
                        "Xuangjing Huang",
                        "Lide Wu"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2010,
                    "rawString": "Lei Zhang, Bing Liu, Suk Hwan Lim and Eamonn O\u2019Brien-Strain. 2010. Extracting and Ranking Product Features in Opinion Documents. In Proceedings of COLING 2010.",
                    "marker": "Zhang, Liu, 2010",
                    "title": "Suk Hwan Lim and Eamonn O\u2019Brien-Strain.",
                    "booktitle": "In Proceedings of COLING",
                    "authors": {"author": [
                        "Lei Zhang",
                        "Bing Liu"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2009,
                    "rawString": "Qi Zhang, Yuanbin Wu, Tao Li, Mitsunori Ogihara, Joseph Johnson, Xuanjing Huang. 2009. Mining Product Reviews Based on Shallow Dependency Parsing, In Proceedings of SIGIR 2009.",
                    "marker": "Zhang, Wu, Li, Ogihara, Johnson, 2009",
                    "contexts": {"context": {
                        "startWordPosition": 1428,
                        "position": 9316,
                        "citStr": "Zhang et al., 2009",
                        "content": "Finally, we give the conclusion and the future work. 2 Related Work Many studies have focused on the task of opinion target extraction, such as (Hu et al., 2004; Ding et al., 2008; Liu et al., 2006; Popescu et al., 2005; Wu et al., 2005; Wang et al., 2008; Li et al., 2010; Su et al., 2008; Li et al., 2006). In general, the existing approaches can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling task (Jin et al. 2009; Li et al. 2010; Wu et al., 2009; Ma et al. 2010; Zhang et al., 2009). Jin et al. (2009) proposed a lexicalized HMM model to perform opinion mining. Li et al. (2010) proposed a Skip-Tree CRF model for opinion target extraction. Their methods exploited three structures including linear-chain structure, syntactic structure, and conjunction structure. In addition, Wu et al. (2009) utilized a SVM classifier to identify relations between opinion targets and opinion expressions by leveraging phrase dependency parsing. The main limitation of these supervised methods is that labeling training data for each domain is impracticable because of the diversity of the review",
                        "endWordPosition": 1431
                    }},
                    "title": "Xuanjing Huang.",
                    "booktitle": "In Proceedings of SIGIR",
                    "authors": {"author": [
                        "Qi Zhang",
                        "Yuanbin Wu",
                        "Tao Li",
                        "Mitsunori Ogihara",
                        "Joseph Johnson"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2011,
                    "rawString": "Guangyou Zhou, Li Cai, Jun Zhao and Kang Liu. 2011. Phrase-based Translation Model for Question Retrieval in Community Question Answer Archives. In Proceedings of ACL 2011.",
                    "marker": "Zhou, Cai, Zhao, Liu, 2011",
                    "contexts": {"context": {
                        "startWordPosition": 2100,
                        "position": 13768,
                        "citStr": "Zhou et al., 2011",
                        "content": ", which have been widely adopted in previous work (Hu et al., 2004; Ding et al., 2008; Wang et al., 2008; Qiu et al., 2011). Thus, our aim is to find potential opinion relations between nouns/noun phrases and adjectives in sentences, and calculate the associations between them. As mentioned in the first section, we formulate opinion relation identification as a word alignment task. We employ the word-based translation model (Brown et al. 1993) to perform monolingual word alignment, which has been widely used in many tasks, such as collocation extraction (Liu et al., 2009), question retrieval (Zhou et al., 2011) and so on. In our method, every sentence is replicated to generate a parallel corpus, and we apply the bilingual word alignment algorithm to the monolingual scenario to align a noun/noun phase with its modifier. Given a sentence with words A =argmax ( |) P A S (1) ( i , a i ) S = {w\u201e w2, ..., wn } , the word alignment A = {(i, a;) I i E [l, n] } can be obtained by maximizing the word alignment probability of the sentence as follows. ˆ A where means that a noun/noun phrase at position i is aligned with an adjective at position a; . If we directly use this alignment model to our task, a noun/no",
                        "endWordPosition": 2103
                    }},
                    "title": "Phrase-based Translation Model for Question Retrieval in Community Question Answer Archives.",
                    "booktitle": "In Proceedings of ACL",
                    "authors": {"author": [
                        "Guangyou Zhou",
                        "Li Cai",
                        "Jun Zhao",
                        "Kang Liu"
                    ]}
                },
                {
                    "valid": true,
                    "date": 2009,
                    "rawString": "Jingbo Zhu, Huizhen Wang, Benjamin K. Tsou and Muhua Zhu. 2009. Multi-aspect Opinion Polling from Textual Reviews. In Proceedings of CIKM 2009.",
                    "marker": "Zhu, Wang, Tsou, Zhu, 2009",
                    "contexts": {"context": {
                        "startWordPosition": 3853,
                        "position": 24513,
                        "citStr": "Zhu et al., 2009",
                        "content": "0.80 0.75 0.70 0.82 0.76 0.80 0.84 0.82 Table 4: Experiments on Large Methods P D1 F P D2 F P D3 F P D4 F P D5 F R R R R R Hu 0.75 0.82 0.78 0.71 0.79 0.75 0.72 0.76 0.74 0.69 0.82 0.75 0.74 0.80 0.77 DP 0.87 0.81 0.84 0.90 0.81 0.85 0.90 0.86 0.88 0.81 0.84 0.82 0.92 0.86 0.89 Zhang 0.83 0.84 0.83 0.86 0.85 0.85 0.86 0.88 0.87 0.80 0.85 0.83 0.86 0.86 0.86 Ours 0.84 0.85 0.84 0.87 0.85 0.86 0.88 0.89 0.88 0.81 0.85 0.83 0.89 0.87 0.88 Table 5: Experiments on Customer Review Dataset each word is assigned. Stanford NLP tool5 is used to perform POS-tagging and dependency parsing. The method in (Zhu et al., 2009) is used to identify noun phrases. We select precision, recall and Fmeasure as the evaluation metrics. We also perform a significant test, i.e., a t-test with a default significant level of 0.05. 4.2 Our Methods vs. State-of-art Methods To prove the effectiveness of our method, we select the following state-of-art unsupervised methods as baselines for comparison. 1) Hu is the method described in (Hu et al., 2004), which extracted opinion targets by using adjacent rule. 2) DP is the method described in (Qiu et al., 2011), which used Double Propagation algorithm to extract opinion targets depend",
                        "endWordPosition": 3856
                    }},
                    "title": "Multi-aspect Opinion Polling from Textual Reviews.",
                    "booktitle": "In Proceedings of CIKM",
                    "authors": {"author": [
                        "Jingbo Zhu",
                        "Huizhen Wang",
                        "Benjamin K Tsou",
                        "Muhua Zhu"
                    ]}
                }
            ]}
        }
    ]
}}